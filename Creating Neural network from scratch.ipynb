{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.7 (default, May  6 2020, 11:45:54) [MSC v.1916 64 bit (AMD64)]\n",
      "Numpy : 1.18.1\n",
      "Matplotlib: 3.1.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Python:\",sys.version)\n",
    "print(\"Numpy :\",np.__version__)\n",
    "print(\"Matplotlib:\",matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=[1.2,5.1,2.1]\n",
    "weights=[3.1,2.1,8.7]\n",
    "bias=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.7\n"
     ]
    }
   ],
   "source": [
    "output=inputs[0]*weights[0]+inputs[1]*weights[1]+inputs[2]*weights[2]+bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "inputs=[1,2,3]\n",
    "weights=[0.2,0.8,-0.5]\n",
    "bias=2\n",
    "output=inputs[0]*weights[0]+inputs[1]*weights[1]+inputs[2]*weights[2]+bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.3, 4.1000000000000005, 3.19]\n"
     ]
    }
   ],
   "source": [
    "inputs=[1,2,3,4]\n",
    "weights1=[0.2,0.8,-0.5,1.0]\n",
    "weights2=[0.5,0.91,0.26,-0.5]\n",
    "weights3=[0.26,-0.27,-0.17,0.87]\n",
    "bias1=2\n",
    "bias2=3\n",
    "bias3=0.5\n",
    "output=[inputs[0]*weights1[0]+inputs[1]*weights1[1]+inputs[2]*weights1[2]+inputs[3]*weights1[3]+bias1,\n",
    "        inputs[0]*weights2[0]+inputs[1]*weights2[1]+inputs[2]*weights2[2]+inputs[3]*weights2[3]+bias2,\n",
    "        inputs[0]*weights3[0]+inputs[1]*weights3[1]+inputs[2]*weights3[2]+inputs[3]*weights3[3]+bias3]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=[[0.2,0.8,-0.5,1.0],[0.5,0.91,0.26,-0.5],[0.26,-0.27,-0.17,0.87]]\n",
    "bias=[1,2,3,0.5]\n",
    "inputs=[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3, 5.1000000000000005, 2.21]\n"
     ]
    }
   ],
   "source": [
    "layer=[]\n",
    "for neuron_weights,neuron_bias in zip(weights,bias):\n",
    "    neuron=0\n",
    "    for n_input,weight in zip(inputs,neuron_weights):\n",
    "        neuron=neuron+(n_input*weight)\n",
    "    neuron+=neuron_bias\n",
    "    layer.append(neuron)\n",
    "print(layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is tensor?\n",
    "\n",
    "# Tensor is an object that can be represented as an array, tensor is not jsut an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=[1,2,3,2.5]\n",
    "weights=[0.2,0.8,-0.5,1.0]\n",
    "bias=2\n",
    "\n",
    "output=np.dot(weights,inputs)+bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=[[0.2,0.8,-0.5,1.0],[0.5,0.91,0.26,-0.5],[0.26,-0.27,-0.17,0.87]]\n",
    "bias=[1,3,0.5]\n",
    "inputs=[1,2,3,4]\n",
    "output=np.dot(weights,inputs)+bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weight is the parameter within a neural network that transforms input data within the network's hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batches,Layers and Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "inputs=[[1,2,3,2.5],\n",
    "        [2,5,-1,2],\n",
    "        [-1.5,2.7,3.3,-0.8]]\n",
    "\n",
    "weights=np.array([[0.2,0.8,-0.5,1.0],[0.5,-0.91,0.26,-0.5],[-0.26,-0.27,0.17,0.87]])\n",
    "bias=[2,3,0.5]\n",
    "output=np.dot(inputs,weights.T)+bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating another layer\n",
    "inputs=[[1,2,3,2.5],\n",
    "        [2,5,-1,2],\n",
    "        [-1.5,2.7,3.3,-0.8]]\n",
    "\n",
    "weights=np.array([[0.2,0.8,-0.5,1.0],[0.5,-0.91,0.26,-0.5],[-0.26,-0.27,0.17,0.87]])\n",
    "bias=[2,3,0.5]\n",
    "\n",
    "weights2=np.array([[0.1,-0.14,0.5],[-0.5,0.12,-0.33],[-0.44,0.73,-0.13]])\n",
    "biases2=[-1,2,-0.5]\n",
    "\n",
    "layer1_output=np.dot(inputs,weights.T)+bias\n",
    "\n",
    "layer2_output=np.dot(layer1_output,weights2.T)+biases2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "print(layer2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[[1,2,3,2.5],\n",
    "        [2,5,-1,2],\n",
    "        [-1.5,2.7,3.3,-0.8]]   #we will assume that this is the input data to the neural netowk\n",
    "np.random.seed(0)\n",
    "\n",
    "# we are now going to define the hidden layers\n",
    "# In case of a neural network there are two ways to intialise a layer.\n",
    "# first is load the trianed model i.e just setting the right weight and biases whaterver is in the model\n",
    "# Second create neural network from scratch\n",
    "# Weights are intialised as random values in the rane -1 to 1 smaller the range better the result\n",
    "# Biases we tend to intialise as zero but there are times when we dont want to do that\n",
    "# becasue in some cases when neuron is not firing then some time if hte neuron is not able to give\n",
    "# output then if we give zero then output will be zero which again given to another layer\n",
    "# will give zero and if next neuron also gets zero that will propagate trhough entire network with zeros\n",
    "# boom entire network is dead so in this we can start biases as non zero number\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights=np.random.randn(n_inputs,n_neurons) # we want the shape that we need to pass in this case \n",
    "        #we need to know size of the input coming and how many neurons do we want to have size will be size o hte single sample in this case gonna pass a  batch\n",
    "        # in this case it is 4\n",
    "        # we want from numpy is to create weight that will be size of n inputs\n",
    "        # multiplied by how many neurons do we want to have so well say n neurons\n",
    "        # earlier shape was numebr of neurons by number of inputs but here it will it is numebr of inptus by nuber of neruons\n",
    "        # the reason is because we if we do forward pass we dpnt need to give transpose everytime\n",
    "        # that means we dont need to use transpose anymore\n",
    "        \n",
    "        self.biases=np.zeros((1,n_neurons))\n",
    "        # shape is one by how many number of neurons we have\n",
    "    def forward(self,inputs): # Forward will only take input \n",
    "#inputs will be actuall training data or input from the previous layer\n",
    "        self.output=np.dot(inputs,self.weights)+self.biases\n",
    "layer1= Layer_Dense(4,5)  # input is how many numeb of features in each sample\n",
    "# 5 is any number you want\n",
    "layer2=Layer_Dense(5,2) #input will be output of lahyer 1 which will be 5 because five neurons five outputs\n",
    "# and output can be any shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14.82959991 -8.39760189]\n",
      " [14.10031472 -1.3404687 ]\n",
      " [20.12497867 -7.29061598]]\n"
     ]
    }
   ],
   "source": [
    "layer1.forward(x)\n",
    "#print(layer1.output)\n",
    "layer2.forward(layer1.output)\n",
    "print(layer2.output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
